IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 9, NO. 3, MARCH 2024 4259
Cooperative Localization in Transportation 5.0
Letian Gao , Xin Xia , Senior Member, IEEE, Zhaoliang Zheng ,
Hao Xiang , Graduate Student Member, IEEE, Zonglin Meng , Graduate Student Member, IEEE, Xu Han , Zewei Zhou , Yi He , Yutong Wang , Zhaojian Li , Yubiao Zhang , and Jiaqi Ma , Senior Member, IEEE
Abstract—In the era of future mobility within Transportation 5.0, autonomy and cooperation across all road users and smart infrastructure stand as the key features to enhance transportation safety, efficiency, and sustainability, supported by cooperative perception, decision-making and planning, and control. An accurate and robust localization system plays a vital role in enabling these modules for future mobility and is constrained by environmental uncertainties and sensing limitations. To achieve precise and resilient localization in this new era, this letter introduces emerging technologies including edge computing, hybrid data-driven and physical model approaches, foundation models as well as parallel intelligence, that are beneficial for next-generation localization systems. On top of these key technologies, by integrating real-world testing and digital twin technology, we further put forward a Decentralized Autonomous Service (DAS)-based cooperative localization framework for future mobility systems to enhance the resilience, robustness, and safety of transportation systems.
Index Terms—Cooperative driving, cooperative localization, localization service, smart infrastructure, transportation 5.0.
I. INTRODUCTION
A
UTONOMOUS and intelligent vehicles have attracted increasing research interest [1], [2], [3], [4], [5]. With the
Manuscript received 9 March 2024; accepted 11 March 2024. Date of publication 18 March 2024; date of current version 3 May 2024. This work was supported in part by the FHWA Center for Excellence on New Mobility and Automated Vehicles Program, in part by the Cooperative Perception and Control for Freeway Traffic System Operations by the Federal Highway Administration Exploratory Advanced Research Program, and in part by California RIMI Program. (Corresponding author: Jiaqi Ma.)
Letian Gao, Xin Xia, Zhaoliang Zheng, Hao Xiang, Zonglin Meng, Xu Han, Zewei Zhou, and Jiaqi Ma are with the UCLA Mobility Lab and FHWA Center of Excellence on New Mobility and Automated Vehicles, University of California, Los Angeles (UCLA), Los Angeles, CA 90095 USA (e-mail: letiangao@g.ucla.edu; x35xia@g.ucla.edu; zhz03@g.ucla.edu; haxiang@g.ucla.edu; meng925@g.ucla.edu; hanxu417@g.ucla.edu; zeweizhou@g.ucla.edu; jiaqima @ucla.edu). Yi He is with the Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan 430063, China, and also with the Engineering Research Center of Transportation Safety, Ministry of Education, Wuhan University of Technology, Wuhan 430063, China (e-mail: heyi@whut.edu.cn). Yutong Wang is with the State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China (e-mail: yutong.wang@ia.ac.cn). Zhaojian Li is with the Department of Mechanical Engineering, Michigan State University, Lansing, MI 48824 USA (e-mail: lizhaoj1@egr.msu.edu). Yubiao Zhang is with the Control and Learning Systems Group at Global R&D, General Motors, Warren, MI 48090 USA (e-mail: yubiao.zhang@gm.com). Color versions of one or more figures in this article are available at https://doi.org/10.1109/TIV.2024.3377163. Digital Object Identifier 10.1109/TIV.2024.3377163
evolution of communication technology and its advanced integration into intelligent vehicles and transportation systems [6], [7], Cooperative Driving Automation (CDA) holds significant promise for enhancing transportation safety, efficiency, and sustainability. CDA, as a subset of autonomous driving, enables vehicles within the network to communicate with other connected vehicles, road users, and smart infrastructures [8], [9]. This communication facilitates the exchange of various types of information, including raw sensor signals, processed results such as detection outcomes, pose information, planned trajectory, and tracking results. By sharing the information, multiple cooperative tasks become achievable, such as cooperative perception [10], cooperative localization [11], cooperative tracking [12], cooperative planning [13], [14], and cooperative control [15]. Pose information of the agents in the cooperative network is the fundamental information for nearly all tasks within cooperative driving [16]. These poses serve as the cornerstone for spatially aligning information from various agents, ensuring that data from different sources can be seamlessly integrated. Consequently, the accuracy of agent poses is paramount for the success of CDA initiatives. While single-vehicle localization methods have seen significant development in recent years, achieving precise and robust localization poses in complex urban driving scenarios remains a big challenge, where sensor range limitations and environmental factors come into play. To address these challenges, multi-sensor fusion frameworks have emerged [17], leveraging vehicle kinematic and dynamic models, multimodal sensors such as Global Navigation Satellite System (GNSS), Inertial Measurement Unit (IMU), LiDAR, camera, and radar [18], [19], [20]. In cooperative driving, the localization could also use the shared information from other Connected and Automated Vehicles (CAVs) and smart infrastructure services [21]. By collaborating with other agents, localization performance can be further enhanced, overcoming the limitations imposed by individual sensor capabilities and environmental variability. The concept of Transportation 5.0 with the framework of the Cyber Physical Social Systems (CPSS) [22], [23] enables one of the most crucial systems of cooperative driving for automated ground vehicles, the cooperative localization system. This system harnesses information from multiple sources to deliver continuous, accurate, robust, and reliable pose information for all connected road users, including both the CAVs and vulnerable road users. Autonomous vehicles typically rely
2379-8858 © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: Texas A M University. Downloaded on June 25,2025 at 05:36:43 UTC from IEEE Xplore. Restrictions apply.


4260 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 9, NO. 3, MARCH 2024
on a single-vehicle localization system to maintain continuous pose information, which, under normal conditions, offers sufficient accuracy for autonomous operation, albeit with potential accuracy degradation in extreme driving conditions. When the single-vehicle localization system cannot meet the requirements for localization performance, accurate localization can be obtained through a cooperative localization system by leveraging external information such as the relative pose among agents and the absolute poses of other agents. Determination of accurate relative pose emerges as the key to successful cooperative localization among CAVs. Cooperative localization has been widely studied in the robotics research area [24]. Presently, much of the cooperative localization research revolves around optimizing the poses of interconnected agents, often assuming either known or directly measurable relative poses, such as those obtainable via range sensors like Ultra-Wideband (UWB) labels [25]. However, outfitting every CAV with additional sensors following the same standard to measure relative pose is impractical in the ground transportation system. Besides, in vehicle applications, real-time performance and safety standards are usually set as priorities, which have requirements for data transmission and computation load. Therefore, an ego vehiclecentered decentralized cooperative localization framework is suitable for cooperative localization in transportation applications in large scale, and each agent has the flexibility to choose high-quality external information and limit the amount of the information to be used. To this end, leveraging existing sensors on CAVs to accurately estimate relative pose becomes crucial for implementing cooperative localization algorithms effectively. Thanks to the rapid advancements in deep learning-based detection methods and Vehicle-to-Everything (V2X) communication techniques, estimating relative pose through detection algorithms or sensor information sharing among different CAVs has become feasible and beneficial for cooperative localization efforts. Furthermore, smart infrastructures that with environment perception capabilities, can also contribute to obtaining relative poses among CAVs through smart infrastructure localization services. All these techniques are supported by the digital twin and foundation intelligence techniques [26], [27], enabling the simulation, verification, and optimization of smart systems, as well as the functionalities of CAVs and smart infrastructures. In this letter, we conducted a review of emerging technologies related to localization in cooperative driving. As a result of our investigation, we propose a Decentralized Autonomous Service (DAS)-based cooperative localization framework that integrates both CAVs and smart infrastructure services. This framework serves as an exemplar of smart infrastructureinvolved cooperative localization for future transportation systems.
II. EMERGING TECHNOLOGIES FOR COOPERATIVE LOCALIZATION
A. Single-Vehicle Localization
While V2X communication can offer a wealth of information surpassing that of a single vehicle’s sensing system, its reliability
may pose challenges [28], therefore the localization cannot only rely on the cooperative localization system. Vehicle-end processing is essential to address issues such as information transmission delays, fault detection, and potential cyber-attacks. To ensure real-time, continuous, and high-frequency pose estimation for downstream driving tasks, each CAV should be equipped with its own single-vehicle localization system. The INS-based Dead Reckoning (DR) method serves as a common foundation for these systems, owing to its high-frequency updates and independent operation [29]. To mitigate the accumulation of errors inherent in INS over time, onboard sensors like the Wheel Speed Sensor (WSS), vehicle kinematics model, and dynamic model are employed for error correction [30]. The GNSS plays a crucial role in providing absolute pose correction, especially in open-sky driving conditions [31]. Additionally, LiDAR [32] and camera-based map matching techniques [33] exhibit significant capabilities for absolute position estimation. With these single-vehicle localization techniques, CAVs can reliably determine their positions in most scenarios. However, in instances where the single-vehicle localization system falters, cooperative localization utilizing information from other agents can enhance system performance.
B. Cooperative Localization Frameworks
The cooperative localization frameworks can be categorized into two main types: centralized and decentralized frameworks [34]. In the centralized framework, all information from different agents in the network is processed in a central computer or a central agent, and the poses of the agents in the group are estimated by this central entity. However, this approach necessitates that all agents are connected to the central processing unit. The computational burden is heavy, making it impractical when dealing with numerous agents in the group. On the other hand, in the decentralized framework, there is no central agent [35]. Instead, each agent is responsible for fusing local information with available data from its neighboring agents. Adopting a decentralized system can lead to improvements in cyber-security, computational load distribution, system robustness, and resilience. Additionally, addressing communication time delays and evaluating information reliability are more manageable within a decentralized framework. Overall, the choice between centralized and decentralized frameworks depends on various factors, including the number of agents involved, computational resources, and the desired level of system robustness and resilience.
C. Inter-Vehicle Relative Pose Estimation
To enable cooperative localization, obtaining inter-vehicle relative pose information is crucial. Traditionally, in robotics, this is achieved through UWB sensors, which serve as additional range sensors for ground vehicles [36]. However, with the advancing sensors integrated into intelligent vehicles, inter-vehicle relative pose estimation can be accomplished using LiDAR, camera, or radar coupled with Artificial Intelligence (AI)-based object detection techniques [37]. For instance, machine learningbased object detection algorithms can identify objects in the
Authorized licensed use limited to: Texas A M University. Downloaded on June 25,2025 at 05:36:43 UTC from IEEE Xplore. Restrictions apply.


IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 9, NO. 3, MARCH 2024 4261
Fig. 1. DAS-based cooperative localization framework.
local frame, providing bounding boxes that enable estimation of the relative pose between detected objects and the ego vehicle. Yet, the accuracy of relative pose estimation derived from bounding boxes may be limited by the performance constraints of the detection algorithm, potentially hindering cooperative localization accuracy. Alternatively, relative pose estimation can be enhanced by leveraging LiDAR scans from different agents and employing point cloud matching techniques, significantly improving accuracy [38]. Moreover, end-to-end learning-based methods utilizing neural features exhibit promising potential for relative pose estimation, offering another avenue for enhancing relative localization accuracy. By leveraging these advanced techniques and sensors, the inter-vehicle relative pose can be estimated more accurately, and serve as pose measurements or localization constraints, so that the cooperative localization systems can achieve higher accuracy and reliability, thereby improving overall localization performance for intelligent vehicles.
D. Smart Infrastructure Service
Smart infrastructures are used to provide information and services to road users, manage traffic, and offer guidance [39]. Smart infrastructure can be a Roadside Unit (RSU), smart intersection system, or even a label along the road that contains specific information and provides service for users. Their significance in localization tasks lies in their pre-known and accurate positions. By estimating the relative pose between a CAV and a smart infrastructure, the absolute pose of the CAV can be determined, providing essential absolute position measurements. Besides, smart infrastructures store geographic information about the surrounding area and can transmit data such as local High-definition (HD) maps to CAVs via V2X communication [40], or the users could autonomously read the stored information from the smart infrastructure with labels, facilitating the localization process. Additionally, smart infrastructures equipped with environment perception systems
can share perception results with connected road users, enhancing localization performance through information fusion. Moreover, smart infrastructures with edge computing systems can leverage gathered pose information from CAVs to perform cooperative localization of connected road users within communication range. The resulting localization results can then be disseminated to road users for reference, further improving overall localization accuracy and reliability [27]. In essence, smart infrastructures serve as critical components in the localization ecosystem, leveraging their accurate positioning and datasharing capabilities to enhance the localization performance of intelligent vehicles and improve overall traffic management and safety.
E. Digital Twin, Large Models, and Parallel Intelligence
The concept of a digital twin serves as a bridge between the virtual and physical worlds [41]. By constructing a virtual environment using real-world data and physical models, we gain the ability to simulate diverse scenarios and collect vast amounts of data to develop and refine algorithms. This simulation capability greatly expedites algorithm development and facilitates the accumulation of valuable insights [42]. However, the efficacy of algorithms ultimately relies on real-world verification and fine-tuning using actual data. The synergy between the virtual and physical worlds, facilitated by the digital twin, enables continuous improvement of systems in real-time. For instance, localization performance is highly sensitive to various scenarios, making it essential to simulate a wide array of long-tail scenarios and corner cases in the virtual environment. This simulation helps optimize localization algorithms based on real-world experience. Additionally, validating localization algorithms through long-term tests in the physical world ensures their robustness and reliability [43]. The rapid advancement of large AI models, including vision models and language models, has significantly enhanced the
Authorized licensed use limited to: Texas A M University. Downloaded on June 25,2025 at 05:36:43 UTC from IEEE Xplore. Restrictions apply.


4262 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 9, NO. 3, MARCH 2024
capabilities of cooperative driving systems including the cooperative localization system [44]. By leveraging foundation modelbased systems and integrating with digital twin techniques and parallel intelligence architectures, AI models offer deep insights into driving environments. These advanced AI models play a crucial role in various aspects of cooperative driving. As for cooperative localization, vision models, for instance, enable accurate detection and recognition of objects, pedestrians, and road signs, enhancing situational awareness for vehicles. The pose information of the objects is one of the perception results from the AI models, it can serve as a measurement for the localization fusion algorithm and can be transmitted to other agents as a localization service for cooperative localization tasks on other agents’ end. Besides, Language models facilitate natural language understanding and communication between vehicles and infrastructure, enabling seamless coordination and collaboration. The combination model of the vision model and language model could provide an understanding of the current traffic environments by using visual and language prompts. For example, in a cooperative localization task, the model could help choose the appropriate agents for cooperation, the agents that are uniformly distributed around the ego agent are more beneficial for cooperative localization. In summary, the application of large AI models, coupled with digital twin techniques and parallel intelligence architectures, offers great potential for advancing cooperative driving systems. These technologies empower vehicles and infrastructure to collaborate intelligently, leading to safer, more efficient, and more sustainable transportation systems.
III. DECENTRALIZED AUTONOMOUS SERVICE (DAS)-BASED COOPERATIVE LOCALIZATION FRAMEWORK
A. Cooperative Localization Framework Based on DAS
In automated vehicle applications, ensuring system safety is essential. The localization system of each CAV serves as a crucial foundation for autonomous driving, requiring robustness and the capability to isolate erroneous external information, particularly in cooperative driving environments. To this end, a decentralized framework is appropriate for future intelligent transportation systems [45]. We propose a Decentralized Autonomous Service (DAS)-based cooperative localization framework as shown in Fig. 1. In our DAS-based cooperative localization framework, we treat information transmission among agents as a service. Each agent within the network has the flexibility to decide whether to utilize the localization service. The ego vehicle possesses its own local localization system and can receive information from neighboring agents. The relative pose can be acquired through onboard estimation algorithms using range sensors, leveraging services provided by other agents, or requesting assistance from smart infrastructure. Subsequently, the CAV conducts cooperative localization locally, addressing concerns such as time delay, fault detection, and information filtering based on the quality of received data. The smart infrastructure, equipped with sensing and computing capabilities, can estimate relative poses
among CAVs within its sensing and communication range. It can then offer localization services to CAVs upon request, with the information fused into the cooperative localization algorithm. In this decentralized cooperative localization framework, the participation or absence of a CAV in the cooperative network has minimal impact on the cooperative localization of other CAVs. Consequently, the system’s robustness, safety, and fault tolerance are enhanced, ensuring reliable localization performance even in dynamic and complex environments. As a practical application of the proposed DAS-based cooperative localization framework, the UCLA smart intersection [27] offers localization services for the cooperative localization of CAVs within its local network. Equipped with advanced sensors such as cameras, radar, and LiDAR, it generates sensing signals used by machine learning algorithms for tasks like object detection, tracking, and prediction. Moreover, the intersection collaborates with other connected road users, leveraging 5G Cellular V2X (C-V2X) communication to enhance perception abilities. In complex urban driving environments where localization accuracy can be affected by various factors such as obstacles, buildings, and weather, the smart intersection offers localization services to potential road users by leveraging its precisely known localization and robust perception and computation capabilities. Supported by digital twin and parallel intelligence techniques, the smart intersection provides CAVs with real-time detection results, which can be used for inter-vehicle relative pose calculation. Furthermore, the smart intersection’s edge computing system stores essential maps, including HD maps, neural feature maps, and point cloud maps. By tapping into these resources, it delivers localization services to CAVs. Through the integration of these services, CAVs can conduct cooperative localization, leveraging all available information to reach a local consensus for localization. The smart intersection exemplifies the integration of advanced sensing, communication, and computation technologies to support cooperative localization in dynamic urban environments, ultimately enhancing the safety and efficiency of transportation systems.
B. Challenges and Insights of DAS for Future Cooperative Localization
In future transportation systems, it’s imperative for each agent to possess its own localization system to meet safety, continuity, and robustness requirements. Additionally, agents must have the capability to fuse information from other agents to engage in cooperative localization, thereby enhancing overall localization performance. In the proposed decentralized framework, the localization service among agents assumes a critical role, facilitating improved localization performance for all participants. However, deploying a DAS-based cooperative localization framework presents several challenges that require further study and exploration: Time synchronization: To fuse the information from different agents and different sensors, the timestamps of all the signals need to be synchronized. Besides, the time delay caused by transmission and synchronization also needs to be dealt with.
Authorized licensed use limited to: Texas A M University. Downloaded on June 25,2025 at 05:36:43 UTC from IEEE Xplore. Restrictions apply.


IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 9, NO. 3, MARCH 2024 4263
Reliability and Resilience: In cooperative localization, each agent receives information from other agents’ services and also sends information to the network. The quality of the information is difficult to assess, and a common standard is needed to normalize the quality indicators of the same kind of information from different agents so that the fusion algorithm can weigh the information. The false information from cyber-attacks also needs to be detected and isolated from the algorithm. Interoperability: Ensuring seamless communication and interoperability between diverse localization systems employed by different agents is essential for effective cooperative localization. Developing standardized protocols and interfaces will be crucial to address this challenge.
Interaction of information from foundation models of different agents: The machine learning, digital twin, and foundation models support the basic functions of the cooperative driving systems, which contribute to the cooperative localization system. Different agents in the cooperative network may use different foundation models, leading to different outputs. It is still need to study the information fusion with domain gap, especially when fusing the intermediate information from different agents.
IV. CONCLUSION
We discussed the emerging technologies that support cooperative localization in transportation 5.0. The information transmission among agents is defined as service, and a DAS-based cooperative localization framework involving CAVs and smart infrastructures is proposed to enhance the accuracy, robustness, and resilience of the future cooperative localization system.
REFERENCES
[1] L. Chen, J. Xie, X. Zhang, J. Deng, S. Ge, and F.-Y. Wang, “Mining 5.0: Concept and framework for intelligent mining systems in CPSS,” IEEE Trans. Intell. Veh., vol. 8, no. 6, pp. 3533–3536, Jun. 2023. [2] L. Chen et al., “Milestones in autonomous driving and intelligent vehicles: Survey of surveys,” IEEE Trans. Intell. Veh., vol. 8, no. 2, pp. 1046–1056, Feb. 2023. [3] J. Ma, E. Leslie, A. Ghiasi, Z. Huang, and Y. Guo, “Empirical analysis of a freeway bundled connected-and-automated vehicle application using experimental data,” J. Transp. Eng., Part A: Syst., vol. 146, no. 6, 2020, Art. no. 04020034, doi: 10.1061/JTEPBS.0000345. [4] X. Xia et al., “An automated driving systems data acquisition and analytics platform,” Transp. Res. Part C: Emerg. Technol., vol. 151, 2023, Art. no. 104120. [5] D. Chen, Y. Kim, and A. G. Stefanopoulou, “Predictive equivalent consumption minimization strategy with segmented traffic information,” IEEE Trans. Veh. Technol., vol. 69, no. 12, pp. 14377–14390, Dec. 2020. [6] S. Teng et al., “Motion planning for autonomous driving: The state of the art and future perspectives,” IEEE Trans. Intell. Veh., vol. 8, no. 6, pp. 3692–3711, Jun. 2023. [7] J. Yang, Q. Ni, G. Luo, Q. Cheng, L. Oukhellou, and S. Han, “A trustworthy Internet of Vehicles: The DAO to safe, secure, and collaborative autonomous driving,” IEEE Trans. Intell. Veh., vol. 8, no. 12, pp. 4678–4681, Dec. 2023. [8] Z. Zheng, X. Han, X. Xia, L. Gao, H. Xiang, and J. Ma, “OpenCDA-ROS: Enabling seamless integration of simulation and real-world cooperative driving automation,” IEEE Trans. Intell. Veh., vol. 8, no. 7, pp. 3775–3780, Jul. 2023. [9] Z. Meng, X. Xia, R. Xu, W. Liu, and J. Ma, “HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,” IEEE Trans. Intell. Veh., vol. 8, no. 8, pp. 4069–4080, Aug. 2023.
[10] S. Teng et al., “FusionPlanner: A multi-task motion planner for mining trucks via multi-sensor fusion,” Mech. Syst. Signal Process., vol. 208, 2024, Art. no. 111051. [Online]. Available: https://www.sciencedirect. com/science/article/pii/S0888327023009597 [11] J. Zhao, Y. Zhang, S. Ni, and Q. Li, “Bayesian cooperative localization with NLOS and malicious vehicle detection in GNSS-challenged environments,” IEEE Access, vol. 8, pp. 85686–85697, 2020. [12] J. Betz et al., “Autonomous vehicles on the edge: A survey on autonomous vehicle racing,” IEEE Open J. Intell. Transp. Syst., vol. 3, pp. 458–488, 2022. [13] C. Ziegler and J. Adamy, “Anytime tree-based trajectory planning for urban driving,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 48–57, 2023. [14] N. Rajesh, Y. Zheng, and B. Shyrokau, “Comfort-oriented motion planning for automated vehicles using deep reinforcement learning,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 348–359, 2023. [15] M. Hu, X. Wang, Y. Bian, D. Cao, and H. Wang, “Disturbance observerbased cooperative control of vehicle platoons subject to mismatched disturbance,” IEEE Trans. Intell. Veh., vol. 8, no. 4, pp. 2748–2758, Apr. 2023. [16] K. Golestan, F. Sattar, F. Karray, M. Kamel, and S. Seifzadeh, “Localization in vehicular ad hoc networks using data fusion and V2V communication,” Comput. Commun., vol. 71, pp. 61–72, 2015. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0140366415002583 [17] L. Gao, X. Xia, Z. Zheng, and J. Ma, “GNSS/IMU/LiDAR fusion for vehicle localization in urban driving environments within a consensus framework,” Mech. Syst. Signal Process., vol. 205, 2023, Art. no. 110862. [18] M. Sakthi, M. Arvinte, and H. Vikalo, “Automotive RADAR sub-sampling via object detection networks: Leveraging prior signal information,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 858–869, 2023.
[19] X. Xia, P. Hang, N. Xu, Y. Huang, L. Xiong, and Z. Yu, “Advancing estimation accuracy of sideslip angle by fusing vehicle kinematics and dynamics information with fuzzy logic,” IEEE Trans. Veh. Technol., vol. 70, no. 7, pp. 6577–6590, Jul. 2021. [20] W. Liu, X. Xia, L. Xiong, Y. Lu, L. Gao, and Z. Yu, “Automated vehicle sideslip angle estimation considering signal measurement characteristic,” IEEE Sensors J., vol. 21, no. 19, pp. 21675–21687, Oct. 2021. [21] F. A. Santos, A. T. Akabane, R. S. Yokoyama, A. A. F. Loureiro, and L. A. Villas, “A roadside unit-based localization scheme to improve positioning for vehicular networks,” in Proc. IEEE 84th Veh. Technol. Conf., 2016, pp. 1–5. [22] F.-Y. Wang and J. J. Zhang, “Transportation 5.0 in CPSS: Towards ACPbased society-centered intelligent transportation,” in Proc. IEEE 20th Int. Conf. Intell. Transp. Syst., 2017, pp. 762–767.
[23] F.-Y. Wang et al., “Transportation 5.0: The DAO to safe, secure, and sustainable intelligent transportation systems,” IEEE Trans. Intell. Transp. Syst., vol. 24, no. 10, pp. 10262–10278, Oct. 2023. [24] L. C. Carrillo-Arce, E. D. Nerurkar, J. L. Gordillo, and S. I. Roumeliotis, “Decentralized multi-robot cooperative localization using covariance intersection,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 2013, pp. 1412–1417. [25] J. Xin, G. Xie, B. Yan, M. Shan, P. Li, and K. Gao, “Multimobile robot cooperative localization using ultrawideband sensor and GPU acceleration,” IEEE Trans. Automat. Sci. Eng., vol. 19, no. 4, pp. 2699–2710, Oct. 2022. [26] Z. Hu, S. Lou, Y. Xing, X. Wang, D. Cao, and C. Lv, “Review and perspectives on driver digital twin and its enabling technologies for intelligent vehicles,” IEEE Trans. Intell. Veh., vol. 7, no. 3, pp. 417–440, Sep. 2022. [27] X. Han et al., “Foundation intelligence for smart infrastructure services in transportation 5.0,” IEEE Trans. Intell. Veh., vol. 9, no. 1, pp. 39–47, Jan. 2024. [28] S. Hasan, S. Girs, and E. Uhlemann, “Characterization of transient communication outages into states to enable autonomous fault tolerance in vehicle platooning,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 101–129, 2023. [29] Z. Cai et al., “Dynamics modeling for autonomous container trucks considering unknown parameters,” IEEE Trans. Intell. Veh., to be published, doi: 10.1109/TIV.2024.3362386. [30] L. Gao, L. Xiong, X. Xia, Y. Lu, Z. Yu, and A. Khajepour, “Improved vehicle localization using on-board sensors and vehicle lateral velocity,” IEEE Sensors J., vol. 22, no. 7, pp. 6818–6831, Apr. 2022. [31] L. Xiong et al., “IMU-based automated vehicle body sideslip angle and attitude estimation aided by GNSS using parallel adaptive Kalman filters,” IEEE Trans. Veh. Technol., vol. 69, no. 10, pp. 10668–10680, Oct. 2020. [32] X. Xia, N. P. Bhatt, A. Khajepour, and E. Hashemi, “Integrated inertialLiDAR-based map matching localization for varying environments,” IEEE Trans. Intell. Veh., vol. 8, no. 10, pp. 4307–4318, Oct. 2023.
Authorized licensed use limited to: Texas A M University. Downloaded on June 25,2025 at 05:36:43 UTC from IEEE Xplore. Restrictions apply.


4264 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 9, NO. 3, MARCH 2024
[33] G. Bresson, Z. Alsayed, L. Yu, and S. Glaser, “Simultaneous localization and mapping: A survey of current trends in autonomous driving,” IEEE Trans. Intell. Veh., vol. 2, no. 3, pp. 194–220, Sep. 2017. [34] T. R. Wanasinghe et al., “Decentralized cooperative localization approach for autonomous multirobot systems,” J. Robot., vol. 2016, 2016, Art. no. 2560573. [35] E. Gutierrez, “Decentralized cooperative localization for multi-robot systems in challenging environments,” M.S. thesis, College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA, 2022. [36] J. Liu and G. Hu, “Relative localization estimation for multiple robots via the rotating ultra-wideband tag,” IEEE Robot. Automat. Lett., vol. 8, no. 7, pp. 4187–4194, Jul. 2023. [37] Y. Qian, X. Wang, H. Zhuang, C. Wang, and M. Yang, “3-D vehicle detection enhancement using tracking feedback in sparse point clouds environments,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 471–480, 2023. [38] L. Gao, H. Xiang, X. Xia, and J. Ma, “Multi-sensor fusion for vehicle-to-vehicle cooperative localization with object detection and point cloud matching,” IEEE Sensors J., to be published, doi: 10.1109/JSEN.2024.3365718. [39] X. Dai, M. Vallati, R. Guo, Y. Wang, S. Han, and Y. Lin, “The road ahead: DAO-secured V2X infrastructures for safe and smart vehicular management,” IEEE Trans. Intell. Veh., vol. 8, no. 12, pp. 4674–4677, Dec. 2023.
[40] K. Bandi, S. Shailendra, and C. Varanasi, “CV2X-PC5 vehicle-based tolling transaction system,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 431–438, 2023. [41] S. Kitajima, H. Chouchane, J. Antona-Makoshi, N. Uchida, and J. Tajima, “A nationwide impact assessment of automated driving systems on traffic safety using multiagent traffic simulations,” IEEE Open J. Intell. Transp. Syst., vol. 3, pp. 302–312, 2022. [42] E. Thonhofer et al., “Infrastructure-based digital twins for cooperative, connected, automated driving and smart road services,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 311–324, 2023. [43] M. Kloock, P. Scheffe, O. Gress, and B. Alrifaee, “An architecture for experiments in connected and automated vehicles,” IEEE Open J. Intell. Transp. Syst., vol. 4, pp. 175–186, 2023. [44] C. Wu, Z. Cai, Y. He, and X. Lu, “A review of vehicle group intelligence in a connected environment,” IEEE Trans. Intell. Veh., vol. 9, no. 1, pp. 1865–1889, Jan. 2024. [45] Y. Chen, H. Zhang, and F.-Y. Wang, “Society-centered and DAO-powered sustainability in transportation 5.0: An intelligent vehicles perspective,” IEEE Trans. Intell. Veh., vol. 8, no. 4, pp. 2635–2638, Apr. 2023.
Authorized licensed use limited to: Texas A M University. Downloaded on June 25,2025 at 05:36:43 UTC from IEEE Xplore. Restrictions apply.